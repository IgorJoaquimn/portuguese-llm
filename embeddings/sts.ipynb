{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609059d4",
   "metadata": {},
   "source": [
    "# BERT Portuguese STS Embeddings\n",
    "\n",
    "This notebook generates embeddings using `neuralmind/bert-large-portuguese-cased` model on the `merged_data_lemm.parquet` dataset efficiently and stores the results with row IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15baa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquino/miniconda3/envs/name_generator/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46207f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (24000, 27)\n",
      "Columns: ['messageId', 'message', 'trait', 'original_prompt', 'model', 'response', 'responseId', 'udpipe_result', 'MLC', 'MLS', 'DCC', 'CPC', 'profundidade_media', 'profundidade_max', 'ttr', 'lexical_density', 'token_quantity', 'adjective_list', 'substantive_list', 'genero', 'raca', 'regiao', 'localidade', 'unused', 'artigo', 'pronome', 'response_lemm']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageId</th>\n",
       "      <th>message</th>\n",
       "      <th>trait</th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>response</th>\n",
       "      <th>responseId</th>\n",
       "      <th>udpipe_result</th>\n",
       "      <th>MLC</th>\n",
       "      <th>MLS</th>\n",
       "      <th>...</th>\n",
       "      <th>adjective_list</th>\n",
       "      <th>substantive_list</th>\n",
       "      <th>genero</th>\n",
       "      <th>raca</th>\n",
       "      <th>regiao</th>\n",
       "      <th>localidade</th>\n",
       "      <th>unused</th>\n",
       "      <th>artigo</th>\n",
       "      <th>pronome</th>\n",
       "      <th>response_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14afb0c8-a4b2-52d5-9c35-8dd0e13b97de</td>\n",
       "      <td>role=&lt;MessageRole.User: 'user'&gt; content=[TextC...</td>\n",
       "      <td>{'genero': 'homem', 'raca': 'preta', 'regiao':...</td>\n",
       "      <td>&lt;user&gt;\\n    Imagine que você é uma pessoa {{ge...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Eu sou um homem negro, nascido e criado no Nor...</td>\n",
       "      <td>407b48b9-b0ed-5658-bba7-4180c43cd30c</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>20.272727</td>\n",
       "      <td>24.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 5, 'form': 'negro', 'lemma': 'negro', ...</td>\n",
       "      <td>[{'id': 4, 'form': 'homem', 'lemma': 'homem', ...</td>\n",
       "      <td>homem</td>\n",
       "      <td>preta</td>\n",
       "      <td>nortista</td>\n",
       "      <td>brasileira</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>ele</td>\n",
       "      <td>eu ser um homem negro nascer e criar _ em o No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14afb0c8-a4b2-52d5-9c35-8dd0e13b97de</td>\n",
       "      <td>role=&lt;MessageRole.User: 'user'&gt; content=[TextC...</td>\n",
       "      <td>{'genero': 'homem', 'raca': 'preta', 'regiao':...</td>\n",
       "      <td>&lt;user&gt;\\n    Imagine que você é uma pessoa {{ge...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Eu sou um homem preto, nascido e criado no Nor...</td>\n",
       "      <td>68156cbb-c93c-5d05-9ba6-cbb2e6d6ee55</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 5, 'form': 'preto', 'lemma': 'preto', ...</td>\n",
       "      <td>[{'id': 4, 'form': 'homem', 'lemma': 'homem', ...</td>\n",
       "      <td>homem</td>\n",
       "      <td>preta</td>\n",
       "      <td>nortista</td>\n",
       "      <td>brasileira</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>ele</td>\n",
       "      <td>eu ser um homem preto nascer e criar _ em o No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14afb0c8-a4b2-52d5-9c35-8dd0e13b97de</td>\n",
       "      <td>role=&lt;MessageRole.User: 'user'&gt; content=[TextC...</td>\n",
       "      <td>{'genero': 'homem', 'raca': 'preta', 'regiao':...</td>\n",
       "      <td>&lt;user&gt;\\n    Imagine que você é uma pessoa {{ge...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Eu sou um homem negro, nordestino e carrego em...</td>\n",
       "      <td>da84a465-0723-5ccd-a449-65c89840bc1e</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>18.266667</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 5, 'form': 'negro', 'lemma': 'negro', ...</td>\n",
       "      <td>[{'id': 4, 'form': 'homem', 'lemma': 'homem', ...</td>\n",
       "      <td>homem</td>\n",
       "      <td>preta</td>\n",
       "      <td>nortista</td>\n",
       "      <td>brasileira</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>ele</td>\n",
       "      <td>eu ser um homem negro nordestino e carregar em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14afb0c8-a4b2-52d5-9c35-8dd0e13b97de</td>\n",
       "      <td>role=&lt;MessageRole.User: 'user'&gt; content=[TextC...</td>\n",
       "      <td>{'genero': 'homem', 'raca': 'preta', 'regiao':...</td>\n",
       "      <td>&lt;user&gt;\\n    Imagine que você é uma pessoa {{ge...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Eu sou um homem negro, natural do Norte do Bra...</td>\n",
       "      <td>91f9690e-b62d-54dc-a365-9803475f3433</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 5, 'form': 'negro', 'lemma': 'negro', ...</td>\n",
       "      <td>[{'id': 4, 'form': 'homem', 'lemma': 'homem', ...</td>\n",
       "      <td>homem</td>\n",
       "      <td>preta</td>\n",
       "      <td>nortista</td>\n",
       "      <td>brasileira</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>ele</td>\n",
       "      <td>eu ser um homem negro natural _ de o Norte _ d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14afb0c8-a4b2-52d5-9c35-8dd0e13b97de</td>\n",
       "      <td>role=&lt;MessageRole.User: 'user'&gt; content=[TextC...</td>\n",
       "      <td>{'genero': 'homem', 'raca': 'preta', 'regiao':...</td>\n",
       "      <td>&lt;user&gt;\\n    Imagine que você é uma pessoa {{ge...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Eu sou um homem negro, nascido e criado no Nor...</td>\n",
       "      <td>aa059409-4765-5520-9caf-348a2c2911ee</td>\n",
       "      <td># generator = UDPipe 2, https://lindat.mff.cun...</td>\n",
       "      <td>15.722222</td>\n",
       "      <td>25.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 5, 'form': 'negro', 'lemma': 'negro', ...</td>\n",
       "      <td>[{'id': 4, 'form': 'homem', 'lemma': 'homem', ...</td>\n",
       "      <td>homem</td>\n",
       "      <td>preta</td>\n",
       "      <td>nortista</td>\n",
       "      <td>brasileira</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>ele</td>\n",
       "      <td>eu ser um homem negro nascer e criar _ em o No...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              messageId  \\\n",
       "0  14afb0c8-a4b2-52d5-9c35-8dd0e13b97de   \n",
       "1  14afb0c8-a4b2-52d5-9c35-8dd0e13b97de   \n",
       "2  14afb0c8-a4b2-52d5-9c35-8dd0e13b97de   \n",
       "3  14afb0c8-a4b2-52d5-9c35-8dd0e13b97de   \n",
       "4  14afb0c8-a4b2-52d5-9c35-8dd0e13b97de   \n",
       "\n",
       "                                             message  \\\n",
       "0  role=<MessageRole.User: 'user'> content=[TextC...   \n",
       "1  role=<MessageRole.User: 'user'> content=[TextC...   \n",
       "2  role=<MessageRole.User: 'user'> content=[TextC...   \n",
       "3  role=<MessageRole.User: 'user'> content=[TextC...   \n",
       "4  role=<MessageRole.User: 'user'> content=[TextC...   \n",
       "\n",
       "                                               trait  \\\n",
       "0  {'genero': 'homem', 'raca': 'preta', 'regiao':...   \n",
       "1  {'genero': 'homem', 'raca': 'preta', 'regiao':...   \n",
       "2  {'genero': 'homem', 'raca': 'preta', 'regiao':...   \n",
       "3  {'genero': 'homem', 'raca': 'preta', 'regiao':...   \n",
       "4  {'genero': 'homem', 'raca': 'preta', 'regiao':...   \n",
       "\n",
       "                                     original_prompt        model  \\\n",
       "0  <user>\\n    Imagine que você é uma pessoa {{ge...  gpt-4o-mini   \n",
       "1  <user>\\n    Imagine que você é uma pessoa {{ge...  gpt-4o-mini   \n",
       "2  <user>\\n    Imagine que você é uma pessoa {{ge...  gpt-4o-mini   \n",
       "3  <user>\\n    Imagine que você é uma pessoa {{ge...  gpt-4o-mini   \n",
       "4  <user>\\n    Imagine que você é uma pessoa {{ge...  gpt-4o-mini   \n",
       "\n",
       "                                            response  \\\n",
       "0  Eu sou um homem negro, nascido e criado no Nor...   \n",
       "1  Eu sou um homem preto, nascido e criado no Nor...   \n",
       "2  Eu sou um homem negro, nordestino e carrego em...   \n",
       "3  Eu sou um homem negro, natural do Norte do Bra...   \n",
       "4  Eu sou um homem negro, nascido e criado no Nor...   \n",
       "\n",
       "                             responseId  \\\n",
       "0  407b48b9-b0ed-5658-bba7-4180c43cd30c   \n",
       "1  68156cbb-c93c-5d05-9ba6-cbb2e6d6ee55   \n",
       "2  da84a465-0723-5ccd-a449-65c89840bc1e   \n",
       "3  91f9690e-b62d-54dc-a365-9803475f3433   \n",
       "4  aa059409-4765-5520-9caf-348a2c2911ee   \n",
       "\n",
       "                                       udpipe_result        MLC        MLS  \\\n",
       "0  # generator = UDPipe 2, https://lindat.mff.cun...  20.272727  24.777778   \n",
       "1  # generator = UDPipe 2, https://lindat.mff.cun...  22.000000  26.888889   \n",
       "2  # generator = UDPipe 2, https://lindat.mff.cun...  18.266667  27.400000   \n",
       "3  # generator = UDPipe 2, https://lindat.mff.cun...  32.375000  21.583333   \n",
       "4  # generator = UDPipe 2, https://lindat.mff.cun...  15.722222  25.727273   \n",
       "\n",
       "   ...                                     adjective_list  \\\n",
       "0  ...  [{'id': 5, 'form': 'negro', 'lemma': 'negro', ...   \n",
       "1  ...  [{'id': 5, 'form': 'preto', 'lemma': 'preto', ...   \n",
       "2  ...  [{'id': 5, 'form': 'negro', 'lemma': 'negro', ...   \n",
       "3  ...  [{'id': 5, 'form': 'negro', 'lemma': 'negro', ...   \n",
       "4  ...  [{'id': 5, 'form': 'negro', 'lemma': 'negro', ...   \n",
       "\n",
       "                                    substantive_list  genero   raca    regiao  \\\n",
       "0  [{'id': 4, 'form': 'homem', 'lemma': 'homem', ...   homem  preta  nortista   \n",
       "1  [{'id': 4, 'form': 'homem', 'lemma': 'homem', ...   homem  preta  nortista   \n",
       "2  [{'id': 4, 'form': 'homem', 'lemma': 'homem', ...   homem  preta  nortista   \n",
       "3  [{'id': 4, 'form': 'homem', 'lemma': 'homem', ...   homem  preta  nortista   \n",
       "4  [{'id': 4, 'form': 'homem', 'lemma': 'homem', ...   homem  preta  nortista   \n",
       "\n",
       "   localidade  unused artigo pronome  \\\n",
       "0  brasileira              o     ele   \n",
       "1  brasileira              o     ele   \n",
       "2  brasileira              o     ele   \n",
       "3  brasileira              o     ele   \n",
       "4  brasileira              o     ele   \n",
       "\n",
       "                                       response_lemm  \n",
       "0  eu ser um homem negro nascer e criar _ em o No...  \n",
       "1  eu ser um homem preto nascer e criar _ em o No...  \n",
       "2  eu ser um homem negro nordestino e carregar em...  \n",
       "3  eu ser um homem negro natural _ de o Norte _ d...  \n",
       "4  eu ser um homem negro nascer e criar _ em o No...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = \"/home/joaquino/portuguese-llm/data/merged_data_lemm.parquet\"\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923db679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device and model configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"rufimelo/bert-large-portuguese-cased-sts\"\n",
    "max_length = 512\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "\n",
    "# Output directory for embeddings\n",
    "embeddings_dir = \"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"\n",
    "os.makedirs(embeddings_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c975e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model: rufimelo/bert-large-portuguese-cased-sts\n",
      "Model loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load BERT model and tokenizer\n",
    "print(f\"Loading BERT model: {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b7ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"Efficient dataset for BERT embedding generation\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, ids, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.ids = ids\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx]) if self.texts[idx] is not None else \"\"\n",
    "        text_id = self.ids[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'text_id': text_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab38300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_batch(model, dataloader, device):\n",
    "    \"\"\"Generate BERT embeddings for texts in batches\"\"\"\n",
    "    \n",
    "    all_embeddings = []\n",
    "    all_ids = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating embeddings\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            text_ids = batch['text_id']\n",
    "            \n",
    "            # Get model outputs\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Use [CLS] token embeddings (first token) as sentence representation\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            \n",
    "            all_embeddings.append(cls_embeddings)\n",
    "            \n",
    "            # Handle text_ids - it could be a tensor or list depending on the dataloader\n",
    "            if hasattr(text_ids, 'tolist'):\n",
    "                all_ids.extend(text_ids.tolist())\n",
    "            else:\n",
    "                all_ids.extend(text_ids)\n",
    "            \n",
    "            # Free GPU memory\n",
    "            del input_ids, attention_mask, outputs\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # Concatenate all embeddings\n",
    "    embeddings = np.vstack(all_embeddings)\n",
    "    \n",
    "    return embeddings, all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90147eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available text columns: ['response']\n",
      "All columns: ['messageId', 'message', 'trait', 'original_prompt', 'model', 'response', 'responseId', 'udpipe_result', 'MLC', 'MLS', 'DCC', 'CPC', 'profundidade_media', 'profundidade_max', 'ttr', 'lexical_density', 'token_quantity', 'adjective_list', 'substantive_list', 'genero', 'raca', 'regiao', 'localidade', 'unused', 'artigo', 'pronome', 'response_lemm']\n",
      "Using text column: 'response'\n",
      "Data shape after cleaning: (24000, 27)\n",
      "Using responseId as identifier for embeddings\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for embedding generation\n",
    "# Check what text column to use\n",
    "text_columns = ['response', 'text', 'content', 'lemmatized_text']\n",
    "available_columns = [col for col in text_columns if col in df.columns]\n",
    "\n",
    "print(f\"Available text columns: {available_columns}\")\n",
    "print(f\"All columns: {list(df.columns)}\")\n",
    "\n",
    "# Use the first available text column or 'response' as default\n",
    "text_column = available_columns[0] if available_columns else 'response'\n",
    "print(f\"Using text column: '{text_column}'\")\n",
    "\n",
    "# Check if responseId column exists\n",
    "if 'responseId' not in df.columns:\n",
    "    raise ValueError(\"Column 'responseId' not found in dataset. Available columns: \" + str(list(df.columns)))\n",
    "\n",
    "# Clean data - remove empty texts and missing responseIds\n",
    "df_clean = df[\n",
    "    df[text_column].notna() & \n",
    "    (df[text_column].str.strip() != '') &\n",
    "    df['responseId'].notna()\n",
    "].copy()\n",
    "\n",
    "print(f\"Data shape after cleaning: {df_clean.shape}\")\n",
    "print(f\"Using responseId as identifier for embeddings\")\n",
    "\n",
    "# Reset index for consistent processing but keep responseId\n",
    "df_clean = df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f176837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24000 texts...\n",
      "Sample text: Eu sou um homem negro, nascido e criado no Norte do Brasil. Minha pele tem um tom profundo, que carrega histórias e ancestralidade, refletindo a rica cultura da minha região. Cresci rodeado pela natur...\n",
      "Sample responseId: 407b48b9-b0ed-5658-bba7-4180c43cd30c\n",
      "Dataset created with 24000 samples\n",
      "Number of batches: 1500\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "texts = df_clean[text_column].tolist()\n",
    "response_ids = df_clean['responseId'].tolist()\n",
    "\n",
    "print(f\"Processing {len(texts)} texts...\")\n",
    "print(f\"Sample text: {texts[0][:200]}...\")\n",
    "print(f\"Sample responseId: {response_ids[0]}\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = TextDataset(texts, response_ids, tokenizer, max_length)\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "print(f\"Number of batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec1cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding generation...\n",
      "Estimated time: ~750.0 minutes (approximate)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1500/1500 [14:19<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings shape: (24000, 1024)\n",
      "Number of embedding IDs: 24000\n",
      "Embedding dimension: 1024\n",
      "✓ Embeddings and IDs are properly aligned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "print(\"Starting embedding generation...\")\n",
    "print(f\"Estimated time: ~{len(dataloader) * 0.5:.1f} minutes (approximate)\")\n",
    "\n",
    "embeddings, embedding_ids = generate_embeddings_batch(model, dataloader, device)\n",
    "\n",
    "print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Number of embedding IDs: {len(embedding_ids)}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "\n",
    "# Verify alignment\n",
    "assert len(embedding_ids) == embeddings.shape[0], \"Mismatch between embeddings and IDs\"\n",
    "print(\"✓ Embeddings and IDs are properly aligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f3efcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to disk...\n",
      "✓ Saved embeddings to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/bert_embeddings.npy\n",
      "✓ Saved responseIds to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/response_ids.npy\n",
      "✓ Saved complete embedding data to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/bert_embeddings_with_ids.pkl\n",
      "✓ Saved complete embedding data to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/bert_embeddings_with_ids.pkl\n",
      "✓ Saved DataFrame to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/bert_embeddings_df.parquet\n",
      "✓ Saved metadata to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/metadata.json\n",
      "\n",
      "🎉 All embeddings saved successfully with responseId as identifier!\n",
      "✓ Saved DataFrame to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/bert_embeddings_df.parquet\n",
      "✓ Saved metadata to: /home/joaquino/portuguese-llm/embeddings/bert_embeddings/metadata.json\n",
      "\n",
      "🎉 All embeddings saved successfully with responseId as identifier!\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings to disk\n",
    "print(\"Saving embeddings to disk...\")\n",
    "\n",
    "# 1. Save as numpy arrays (most efficient)\n",
    "embeddings_file = os.path.join(embeddings_dir, \"bert_embeddings.npy\")\n",
    "ids_file = os.path.join(embeddings_dir, \"response_ids.npy\")\n",
    "\n",
    "np.save(embeddings_file, embeddings)\n",
    "np.save(ids_file, np.array(embedding_ids))\n",
    "\n",
    "print(f\"✓ Saved embeddings to: {embeddings_file}\")\n",
    "print(f\"✓ Saved responseIds to: {ids_file}\")\n",
    "\n",
    "# 2. Save as pickle for convenience (includes both embeddings and IDs)\n",
    "pickle_file = os.path.join(embeddings_dir, \"bert_embeddings_with_ids.pkl\")\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'embeddings': embeddings,\n",
    "        'response_ids': embedding_ids,\n",
    "        'model_name': model_name,\n",
    "        'embedding_dim': embeddings.shape[1],\n",
    "        'text_column': text_column\n",
    "    }, f)\n",
    "\n",
    "print(f\"✓ Saved complete embedding data to: {pickle_file}\")\n",
    "\n",
    "# 3. Save as DataFrame for easy analysis\n",
    "embedding_df = pd.DataFrame(embeddings)\n",
    "embedding_df['responseId'] = embedding_ids\n",
    "embedding_df_file = os.path.join(embeddings_dir, \"bert_embeddings_df.parquet\")\n",
    "embedding_df.to_parquet(embedding_df_file, index=False)\n",
    "\n",
    "print(f\"✓ Saved DataFrame to: {embedding_df_file}\")\n",
    "\n",
    "# Create metadata file\n",
    "metadata = {\n",
    "    'model_name': model_name,\n",
    "    'text_column': text_column,\n",
    "    'id_column': 'responseId',\n",
    "    'embedding_dimension': int(embeddings.shape[1]),\n",
    "    'num_samples': int(embeddings.shape[0]),\n",
    "    'max_length': max_length,\n",
    "    'batch_size': batch_size,\n",
    "    'files': {\n",
    "        'embeddings': 'bert_embeddings.npy',\n",
    "        'response_ids': 'response_ids.npy',\n",
    "        'pickle': 'bert_embeddings_with_ids.pkl',\n",
    "        'dataframe': 'bert_embeddings_df.parquet'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_file = os.path.join(embeddings_dir, \"metadata.json\")\n",
    "import json\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved metadata to: {metadata_file}\")\n",
    "print(\"\\n🎉 All embeddings saved successfully with responseId as identifier!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0486e9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Verification ===\n",
      "Loaded embeddings shape: (24000, 1024)\n",
      "Loaded responseIds shape: (24000,)\n",
      "Embeddings match: True\n",
      "ResponseIds match: True\n",
      "\n",
      "Sample embedding (first 10 dimensions): [ 0.28160176  0.13340287  0.08593579 -0.1962112  -0.46568924  0.68999684\n",
      "  1.4194202  -0.0229957  -1.4196646   1.8162141 ]\n",
      "Sample responseId: 407b48b9-b0ed-5658-bba7-4180c43cd30c\n",
      "Sample text: Eu sou um homem negro, nascido e criado no Norte do Brasil. Minha pele tem um tom profundo, que carr...\n",
      "\n",
      "✅ Verification complete!\n",
      "\n",
      "✅ Verification complete!\n"
     ]
    }
   ],
   "source": [
    "# Quick verification and example usage\n",
    "print(\"=== Verification ===\")\n",
    "\n",
    "# Load and verify one format\n",
    "loaded_embeddings = np.load(embeddings_file)\n",
    "loaded_ids = np.load(ids_file)\n",
    "\n",
    "print(f\"Loaded embeddings shape: {loaded_embeddings.shape}\")\n",
    "print(f\"Loaded responseIds shape: {loaded_ids.shape}\")\n",
    "print(f\"Embeddings match: {np.array_equal(embeddings, loaded_embeddings)}\")\n",
    "print(f\"ResponseIds match: {np.array_equal(embedding_ids, loaded_ids)}\")\n",
    "\n",
    "# Show some sample embeddings\n",
    "print(f\"\\nSample embedding (first 10 dimensions): {loaded_embeddings[0][:10]}\")\n",
    "print(f\"Sample responseId: {loaded_ids[0]}\")\n",
    "print(f\"Sample text: {texts[0][:100]}...\")\n",
    "\n",
    "# Memory cleanup\n",
    "del embeddings, loaded_embeddings\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n✅ Verification complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c92e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined. You can use these to load embeddings in other notebooks:\n",
      "- load_bert_embeddings() -> returns (embeddings, response_ids)\n",
      "- load_bert_embeddings_with_metadata() -> returns dict with all metadata\n",
      "- load_bert_embeddings_as_dataframe() -> returns DataFrame with responseId column\n",
      "- get_embedding_by_response_id(response_id) -> returns specific embedding\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for loading embeddings in future work\n",
    "def load_bert_embeddings(embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"):\n",
    "    \"\"\"\n",
    "    Load BERT embeddings from disk\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (embeddings, response_ids) as numpy arrays\n",
    "    \"\"\"\n",
    "    embeddings_file = os.path.join(embeddings_dir, \"bert_embeddings.npy\")\n",
    "    ids_file = os.path.join(embeddings_dir, \"response_ids.npy\")\n",
    "    \n",
    "    embeddings = np.load(embeddings_file)\n",
    "    response_ids = np.load(ids_file)\n",
    "    \n",
    "    return embeddings, response_ids\n",
    "\n",
    "def load_bert_embeddings_with_metadata(embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"):\n",
    "    \"\"\"\n",
    "    Load BERT embeddings with full metadata from pickle file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing embeddings, response_ids, and metadata\n",
    "    \"\"\"\n",
    "    pickle_file = os.path.join(embeddings_dir, \"bert_embeddings_with_ids.pkl\")\n",
    "    \n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_bert_embeddings_as_dataframe(embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"):\n",
    "    \"\"\"\n",
    "    Load BERT embeddings as pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with embeddings and responseId\n",
    "    \"\"\"\n",
    "    df_file = os.path.join(embeddings_dir, \"bert_embeddings_df.parquet\")\n",
    "    return pd.read_parquet(df_file)\n",
    "\n",
    "def get_embedding_by_response_id(response_id, embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"):\n",
    "    \"\"\"\n",
    "    Get embedding for a specific responseId\n",
    "    \n",
    "    Args:\n",
    "        response_id: The responseId to look for\n",
    "        embeddings_dir: Directory containing the embeddings\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The embedding vector for the given responseId, or None if not found\n",
    "    \"\"\"\n",
    "    embeddings, response_ids = load_bert_embeddings(embeddings_dir)\n",
    "    \n",
    "    # Convert to list for index lookup if needed\n",
    "    if not isinstance(response_ids, list):\n",
    "        response_ids = response_ids.tolist()\n",
    "    \n",
    "    try:\n",
    "        idx = response_ids.index(response_id)\n",
    "        return embeddings[idx]\n",
    "    except ValueError:\n",
    "        print(f\"ResponseId {response_id} not found in embeddings\")\n",
    "        return None\n",
    "\n",
    "print(\"Helper functions defined. You can use these to load embeddings in other notebooks:\")\n",
    "print(\"- load_bert_embeddings() -> returns (embeddings, response_ids)\")\n",
    "print(\"- load_bert_embeddings_with_metadata() -> returns dict with all metadata\")  \n",
    "print(\"- load_bert_embeddings_as_dataframe() -> returns DataFrame with responseId column\")\n",
    "print(\"- get_embedding_by_response_id(response_id) -> returns specific embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239d8b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced helper functions for working with responseId:\n",
      "- load_embeddings_dataframe_with_responseId(responseId_first=True)\n",
      "- get_embeddings_by_responseIds(['id1', 'id2', ...])\n",
      "- get_embedding_array_by_responseId('single_id')\n"
     ]
    }
   ],
   "source": [
    "# Improved helper function for loading embeddings as DataFrame with better organization\n",
    "def load_embeddings_dataframe_with_responseId(embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\", \n",
    "                                              responseId_first=True):\n",
    "    \"\"\"\n",
    "    Load BERT embeddings as pandas DataFrame with responseId column\n",
    "    \n",
    "    Args:\n",
    "        embeddings_dir (str): Directory containing the embeddings\n",
    "        responseId_first (bool): If True, puts responseId as the first column for easier access\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with responseId and embedding dimensions\n",
    "                     - If responseId_first=True: columns are ['responseId', '0', '1', ..., 'n']\n",
    "                     - If responseId_first=False: columns are ['0', '1', ..., 'n', 'responseId']\n",
    "    \"\"\"\n",
    "    # Load the parquet file\n",
    "    df_file = os.path.join(embeddings_dir, \"bert_embeddings_df.parquet\")\n",
    "    \n",
    "    if not os.path.exists(df_file):\n",
    "        raise FileNotFoundError(f\"Embedding DataFrame file not found: {df_file}\")\n",
    "    \n",
    "    df = pd.read_parquet(df_file)\n",
    "    \n",
    "    if responseId_first:\n",
    "        # Reorganize columns to put responseId first\n",
    "        embedding_cols = [col for col in df.columns if col != 'responseId']\n",
    "        df = df[['responseId'] + embedding_cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_embeddings_by_responseIds(response_ids_list, embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"):\n",
    "    \"\"\"\n",
    "    Get embeddings for specific responseIds\n",
    "    \n",
    "    Args:\n",
    "        response_ids_list (list): List of responseIds to retrieve\n",
    "        embeddings_dir (str): Directory containing the embeddings\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with embeddings for the specified responseIds\n",
    "    \"\"\"\n",
    "    df = load_embeddings_dataframe_with_responseId(embeddings_dir, responseId_first=True)\n",
    "    \n",
    "    # Filter by responseIds\n",
    "    filtered_df = df[df['responseId'].isin(response_ids_list)]\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        print(f\"No embeddings found for the provided responseIds\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"Found {len(filtered_df)} embeddings out of {len(response_ids_list)} requested responseIds\")\n",
    "    return filtered_df\n",
    "\n",
    "def get_embedding_array_by_responseId(response_id, embeddings_dir=\"/home/joaquino/portuguese-llm/embeddings/bert_embeddings\"):\n",
    "    \"\"\"\n",
    "    Get just the embedding array for a single responseId\n",
    "    \n",
    "    Args:\n",
    "        response_id (str): The responseId to look for\n",
    "        embeddings_dir (str): Directory containing the embeddings\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The embedding vector, or None if not found\n",
    "    \"\"\"\n",
    "    df = load_embeddings_dataframe_with_responseId(embeddings_dir, responseId_first=True)\n",
    "    \n",
    "    # Find the row with the specified responseId\n",
    "    row = df[df['responseId'] == response_id]\n",
    "    \n",
    "    if row.empty:\n",
    "        print(f\"ResponseId {response_id} not found in embeddings\")\n",
    "        return None\n",
    "    \n",
    "    # Return just the embedding values (exclude responseId column)\n",
    "    embedding_cols = [col for col in df.columns if col != 'responseId']\n",
    "    return row[embedding_cols].values[0]\n",
    "\n",
    "print(\"Enhanced helper functions for working with responseId:\")\n",
    "print(\"- load_embeddings_dataframe_with_responseId(responseId_first=True)\")\n",
    "print(\"- get_embeddings_by_responseIds(['id1', 'id2', ...])\")\n",
    "print(\"- get_embedding_array_by_responseId('single_id')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da056a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading DataFrame with responseId as first column ===\n",
      "DataFrame shape: (24000, 1025)\n",
      "Columns (first 5): ['responseId', '0', '1', '2', '3']\n",
      "ResponseId column is first: True\n",
      "\n",
      "First few rows:\n",
      "DataFrame shape: (24000, 1025)\n",
      "Columns (first 5): ['responseId', '0', '1', '2', '3']\n",
      "ResponseId column is first: True\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responseId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407b48b9-b0ed-5658-bba7-4180c43cd30c</td>\n",
       "      <td>0.281602</td>\n",
       "      <td>0.133403</td>\n",
       "      <td>0.085936</td>\n",
       "      <td>-0.196211</td>\n",
       "      <td>-0.465689</td>\n",
       "      <td>0.689997</td>\n",
       "      <td>1.419420</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-1.419665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914445</td>\n",
       "      <td>-1.052605</td>\n",
       "      <td>0.186389</td>\n",
       "      <td>0.624883</td>\n",
       "      <td>0.774898</td>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.088727</td>\n",
       "      <td>0.623736</td>\n",
       "      <td>-0.429235</td>\n",
       "      <td>1.738742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68156cbb-c93c-5d05-9ba6-cbb2e6d6ee55</td>\n",
       "      <td>-0.345559</td>\n",
       "      <td>0.024747</td>\n",
       "      <td>0.020951</td>\n",
       "      <td>-0.021848</td>\n",
       "      <td>-0.736197</td>\n",
       "      <td>0.712839</td>\n",
       "      <td>1.394930</td>\n",
       "      <td>-0.341191</td>\n",
       "      <td>-1.764418</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150340</td>\n",
       "      <td>-1.160325</td>\n",
       "      <td>-0.744703</td>\n",
       "      <td>0.240948</td>\n",
       "      <td>0.705257</td>\n",
       "      <td>0.636925</td>\n",
       "      <td>0.261278</td>\n",
       "      <td>0.685762</td>\n",
       "      <td>-0.413341</td>\n",
       "      <td>1.549394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da84a465-0723-5ccd-a449-65c89840bc1e</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.278898</td>\n",
       "      <td>0.307217</td>\n",
       "      <td>-0.265869</td>\n",
       "      <td>-0.455923</td>\n",
       "      <td>0.532898</td>\n",
       "      <td>1.256891</td>\n",
       "      <td>-0.050374</td>\n",
       "      <td>-1.349318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.045205</td>\n",
       "      <td>-1.101055</td>\n",
       "      <td>0.355464</td>\n",
       "      <td>1.046495</td>\n",
       "      <td>0.737988</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>1.062259</td>\n",
       "      <td>-0.488595</td>\n",
       "      <td>1.866999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             responseId         0         1         2  \\\n",
       "0  407b48b9-b0ed-5658-bba7-4180c43cd30c  0.281602  0.133403  0.085936   \n",
       "1  68156cbb-c93c-5d05-9ba6-cbb2e6d6ee55 -0.345559  0.024747  0.020951   \n",
       "2  da84a465-0723-5ccd-a449-65c89840bc1e  0.374511  0.278898  0.307217   \n",
       "\n",
       "          3         4         5         6         7         8  ...      1014  \\\n",
       "0 -0.196211 -0.465689  0.689997  1.419420 -0.022996 -1.419665  ...  0.914445   \n",
       "1 -0.021848 -0.736197  0.712839  1.394930 -0.341191 -1.764418  ...  1.150340   \n",
       "2 -0.265869 -0.455923  0.532898  1.256891 -0.050374 -1.349318  ...  1.045205   \n",
       "\n",
       "       1015      1016      1017      1018      1019      1020      1021  \\\n",
       "0 -1.052605  0.186389  0.624883  0.774898  0.478640  0.088727  0.623736   \n",
       "1 -1.160325 -0.744703  0.240948  0.705257  0.636925  0.261278  0.685762   \n",
       "2 -1.101055  0.355464  1.046495  0.737988  0.647583  0.006477  1.062259   \n",
       "\n",
       "       1022      1023  \n",
       "0 -0.429235  1.738742  \n",
       "1 -0.413341  1.549394  \n",
       "2 -0.488595  1.866999  \n",
       "\n",
       "[3 rows x 1025 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo: Load DataFrame with responseId as first column\n",
    "print(\"=== Loading DataFrame with responseId as first column ===\")\n",
    "df_with_responseId = load_embeddings_dataframe_with_responseId(responseId_first=True)\n",
    "print(f\"DataFrame shape: {df_with_responseId.shape}\")\n",
    "print(f\"Columns (first 5): {list(df_with_responseId.columns[:5])}\")\n",
    "print(f\"ResponseId column is first: {df_with_responseId.columns[0] == 'responseId'}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_with_responseId.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "name_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
