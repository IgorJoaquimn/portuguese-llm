{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad91cab",
   "metadata": {},
   "source": [
    "# Stylometric and Linguistic Analysis of Parliamentary Discourse\n",
    "\n",
    "This notebook implements comprehensive stylometric and linguistic feature analysis to quantify the structural properties of parliamentary discourse in Portuguese. \n",
    "\n",
    "## Methodology Overview\n",
    "\n",
    "We conduct analysis across four main dimensions:\n",
    "\n",
    "1. **Readability**: Using the Flesch Reading Ease score to assess discourse complexity\n",
    "2. **Lexical Diversity**: Type-Token Ratio (TTR) - already available in dataset \n",
    "3. **Syntactic Structure**: Part-of-Speech (POS) frequency analysis\n",
    "4. **Named Entity Recognition**: Identification of people, organizations, and locations\n",
    "\n",
    "All linguistic processing is performed using the spaCy library with the Portuguese language model `pt_core_news_lg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f3db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Libraries imported successfully!\n",
      "üîß Custom stylometric analyzer loaded!\n",
      "‚ö†Ô∏è  Using pt_core_news_sm (smaller model). For better results, install pt_core_news_lg\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append('/home/igo/faculdade/poc/src')\n",
    "\n",
    "# Import our custom stylometric analyzer\n",
    "from stylometric_analysis import StylometricAnalyzer, process_dataframe\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(\"üîß Custom stylometric analyzer loaded!\")\n",
    "\n",
    "# Check if spaCy Portuguese model is available\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_lg\")\n",
    "    print(\"‚úÖ spaCy Portuguese model (pt_core_news_lg) loaded successfully!\")\n",
    "except IOError:\n",
    "    try:\n",
    "        nlp = spacy.load(\"pt_core_news_sm\")\n",
    "        print(\"‚ö†Ô∏è  Using pt_core_news_sm (smaller model). For better results, install pt_core_news_lg\")\n",
    "    except IOError:\n",
    "        print(\"‚ùå No Portuguese spaCy model found. Please install with:\")\n",
    "        print(\"   python -m spacy download pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb62af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No Portuguese spaCy model found.\n",
      "   Please install with one of:\n",
      "   python -m spacy download pt_core_news_sm\n",
      "   python -m spacy download pt_core_news_lg\n",
      "   We'll continue with a warning - some features may not work properly\n"
     ]
    }
   ],
   "source": [
    "# Check if spaCy Portuguese model is available\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "    print(\"‚úÖ spaCy Portuguese model (pt_core_news_sm) is available\")\n",
    "except IOError:\n",
    "    try:\n",
    "        nlp = spacy.load(\"pt_core_news_lg\")\n",
    "        print(\"‚úÖ spaCy Portuguese model (pt_core_news_lg) is available\")\n",
    "    except IOError:\n",
    "        print(\"‚ùå No Portuguese spaCy model found.\")\n",
    "        print(\"   Please install with one of:\")\n",
    "        print(\"   python -m spacy download pt_core_news_sm\")\n",
    "        print(\"   python -m spacy download pt_core_news_lg\")\n",
    "        print(\"   We'll continue with a warning - some features may not work properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce5736",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "First, we'll load the existing dataset that already contains TTR (Type-Token Ratio) values and other linguistic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d346253c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the sentiment results data\n",
    "data_path = \"/home/igo/faculdade/poc/data/sentiment_results.parquet\"\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"üìä Dataset loaded successfully!\")\n",
    "print(f\"üìà Shape: {df.shape}\")\n",
    "print(f\"üè∑Ô∏è  Columns: {list(df.columns)}\")\n",
    "\n",
    "# Check for existing linguistic metrics\n",
    "existing_metrics = ['ttr', 'MLC', 'MLS', 'DCC', 'CPC', 'profundidade_media', 'profundidade_max', 'lexical_density']\n",
    "available_metrics = [col for col in existing_metrics if col in df.columns]\n",
    "print(f\"\\n‚úÖ Already available linguistic metrics: {available_metrics}\")\n",
    "\n",
    "# Check text columns\n",
    "text_columns = [col for col in df.columns if 'response' in col.lower()]\n",
    "print(f\"üìù Available text columns: {text_columns}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã Sample data:\")\n",
    "display_columns = ['model', 'response', 'ttr', 'sentiment_label'] + available_metrics[:3]\n",
    "available_display_cols = [col for col in display_columns if col in df.columns]\n",
    "print(df[available_display_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c023970",
   "metadata": {},
   "source": [
    "## 2. Calculate Flesch Reading Ease Score\n",
    "\n",
    "The Flesch Reading Ease score quantifies text readability based on average sentence length and word complexity (syllables per word). For Portuguese parliamentary discourse, we expect low scores (including negative values) indicating high complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eee219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stylometric analyzer\n",
    "analyzer = StylometricAnalyzer()\n",
    "\n",
    "# Let's test the Flesch Reading Ease calculation on a sample\n",
    "sample_text = df['response'].dropna().iloc[0] if 'response' in df.columns else \"\"\n",
    "print(\"üß™ Testing Flesch Reading Ease calculation...\")\n",
    "print(f\"Sample text (first 200 chars): {sample_text[:200]}...\")\n",
    "\n",
    "if sample_text:\n",
    "    flesch_score = analyzer.calculate_flesch_reading_ease_pt(sample_text)\n",
    "    print(f\"\\nüìä Flesch Reading Ease Score: {flesch_score}\")\n",
    "    \n",
    "    # Interpret the score\n",
    "    if flesch_score >= 90:\n",
    "        interpretation = \"Very Easy\"\n",
    "    elif flesch_score >= 80:\n",
    "        interpretation = \"Easy\"\n",
    "    elif flesch_score >= 70:\n",
    "        interpretation = \"Fairly Easy\"\n",
    "    elif flesch_score >= 60:\n",
    "        interpretation = \"Standard\"\n",
    "    elif flesch_score >= 50:\n",
    "        interpretation = \"Fairly Difficult\"\n",
    "    elif flesch_score >= 30:\n",
    "        interpretation = \"Difficult\"\n",
    "    else:\n",
    "        interpretation = \"Very Difficult (Parliamentary/Legal complexity)\"\n",
    "    \n",
    "    print(f\"üìù Interpretation: {interpretation}\")\n",
    "else:\n",
    "    print(\"‚ùå No text available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b1cfe",
   "metadata": {},
   "source": [
    "## 3. Part-of-Speech Tagging and Syntactic Analysis\n",
    "\n",
    "We'll analyze the grammatical composition by calculating relative frequencies of main grammatical categories: nouns, verbs, adjectives, and adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test POS frequency analysis on sample text\n",
    "print(\"üß™ Testing POS frequency analysis...\")\n",
    "\n",
    "if sample_text:\n",
    "    pos_frequencies = analyzer.calculate_pos_frequencies(sample_text)\n",
    "    print(f\"üìä POS Frequencies:\")\n",
    "    for pos_type, frequency in pos_frequencies.items():\n",
    "        print(f\"   {pos_type}: {frequency:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüîç Interpretation:\")\n",
    "    print(f\"   ‚Ä¢ High noun frequency ({pos_frequencies['noun_freq']:.1f}%) ‚Üí Nominal/informational style\")\n",
    "    print(f\"   ‚Ä¢ Verb frequency ({pos_frequencies['verb_freq']:.1f}%) ‚Üí Narrative/action-oriented\")\n",
    "    print(f\"   ‚Ä¢ Adjective frequency ({pos_frequencies['adj_freq']:.1f}%) ‚Üí Descriptive/evaluative\")\n",
    "    print(f\"   ‚Ä¢ Adverb frequency ({pos_frequencies['adv_freq']:.1f}%) ‚Üí Subjective discourse\")\n",
    "    \n",
    "    # Detailed POS analysis with spaCy\n",
    "    doc = analyzer.nlp(sample_text[:500])  # Analyze first 500 chars for detailed view\n",
    "    print(f\"\\nüìù Detailed POS analysis (first 500 chars):\")\n",
    "    \n",
    "    pos_examples = {}\n",
    "    for token in doc:\n",
    "        if not token.is_punct and not token.is_space:\n",
    "            if token.pos_ not in pos_examples:\n",
    "                pos_examples[token.pos_] = []\n",
    "            if len(pos_examples[token.pos_]) < 3:  # Show max 3 examples per POS\n",
    "                pos_examples[token.pos_].append(token.text)\n",
    "    \n",
    "    for pos, examples in sorted(pos_examples.items()):\n",
    "        print(f\"   {pos}: {', '.join(examples)}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No text available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e8f3b",
   "metadata": {},
   "source": [
    "## 4. Named Entity Recognition (NER)\n",
    "\n",
    "We'll identify and categorize mentions of people (PER), organizations (ORG), and locations (LOC/GPE) to understand the salience of different actors and themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2942c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Named Entity Recognition on sample text\n",
    "print(\"üß™ Testing Named Entity Recognition...\")\n",
    "\n",
    "if sample_text:\n",
    "    entities = analyzer.extract_named_entities(sample_text)\n",
    "    print(f\"üìä Named Entity Counts:\")\n",
    "    print(f\"   People (PER): {entities['per_count']}\")\n",
    "    print(f\"   Organizations (ORG): {entities['org_count']}\")\n",
    "    print(f\"   Locations (LOC/GPE): {entities['loc_count']}\")\n",
    "    \n",
    "    # Show detailed entities found\n",
    "    doc = analyzer.nlp(sample_text)\n",
    "    print(f\"\\nüìù Detailed entities found:\")\n",
    "    \n",
    "    entities_found = {\"PER\": [], \"ORG\": [], \"LOC/GPE\": []}\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PER\", \"PERSON\"]:\n",
    "            entities_found[\"PER\"].append(ent.text)\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            entities_found[\"ORG\"].append(ent.text)\n",
    "        elif ent.label_ in [\"LOC\", \"GPE\", \"PLACE\"]:\n",
    "            entities_found[\"LOC/GPE\"].append(ent.text)\n",
    "    \n",
    "    for ent_type, ent_list in entities_found.items():\n",
    "        if ent_list:\n",
    "            unique_entities = list(set(ent_list))[:5]  # Show max 5 unique entities\n",
    "            print(f\"   {ent_type}: {', '.join(unique_entities)}\")\n",
    "        else:\n",
    "            print(f\"   {ent_type}: No entities found\")\n",
    "    \n",
    "    # Show all entities with labels for debugging\n",
    "    all_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    if all_entities:\n",
    "        print(f\"\\nüîç All entities found (with labels): {all_entities[:10]}\")\n",
    "    else:\n",
    "        print(f\"\\nüîç No entities found in sample text\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No text available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee79d3",
   "metadata": {},
   "source": [
    "## 5. Process Full Dataset and Add New Columns\n",
    "\n",
    "Now we'll process the entire dataset to add all the new stylometric and linguistic metrics as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process dataset in smaller batches for memory efficiency\n",
    "print(\"üöÄ Starting full dataset processing...\")\n",
    "print(f\"üìä Processing {len(df)} rows in batches...\")\n",
    "\n",
    "# Choose text column to analyze\n",
    "text_column = 'response' if 'response' in df.columns else 'response_lemm'\n",
    "print(f\"üìù Using text column: {text_column}\")\n",
    "\n",
    "# Start with a small sample to test processing time\n",
    "test_sample_size = min(100, len(df))\n",
    "print(f\"\\nüß™ Testing with {test_sample_size} rows first...\")\n",
    "\n",
    "# Process test sample\n",
    "df_test = df.head(test_sample_size).copy()\n",
    "df_test_processed = process_dataframe(df_test, text_column=text_column, batch_size=50)\n",
    "\n",
    "# Check what new columns were added\n",
    "original_columns = set(df.columns)\n",
    "new_columns = [col for col in df_test_processed.columns if col not in original_columns]\n",
    "print(f\"\\n‚úÖ New columns added: {new_columns}\")\n",
    "\n",
    "# Show sample results\n",
    "print(f\"\\nüìã Sample results:\")\n",
    "sample_results = df_test_processed[new_columns + ['model', text_column[:50] if text_column in df_test_processed.columns else 'model']].head(3)\n",
    "print(sample_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the full dataset (this may take some time)\n",
    "# Uncomment the lines below when ready to process the full dataset\n",
    "\n",
    "# print(\"üîÑ Processing full dataset (this may take several minutes)...\")\n",
    "# df_full_processed = process_dataframe(df, text_column=text_column, batch_size=50)\n",
    "\n",
    "# For now, let's work with the test sample to demonstrate the analysis\n",
    "df_processed = df_test_processed.copy()\n",
    "print(f\"\\nüìä Working with processed sample of {len(df_processed)} rows\")\n",
    "\n",
    "# Display summary statistics for new metrics\n",
    "print(f\"\\nüìà Summary Statistics for New Stylometric Metrics:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for col in new_columns:\n",
    "    if df_processed[col].dtype in ['float64', 'int64', 'float32', 'int32']:\n",
    "        stats = df_processed[col].describe()\n",
    "        print(f\"\\n{col.upper().replace('_', ' ')}:\")\n",
    "        print(f\"  Mean: {stats['mean']:.2f}\")\n",
    "        print(f\"  Std:  {stats['std']:.2f}\")\n",
    "        print(f\"  Min:  {stats['min']:.2f}\")\n",
    "        print(f\"  Max:  {stats['max']:.2f}\")\n",
    "\n",
    "# Save processed sample for further analysis\n",
    "output_path = \"/home/igo/faculdade/poc/data/sentiment_results_sample_with_stylometric.parquet\"\n",
    "df_processed.to_parquet(output_path, index=False)\n",
    "print(f\"\\nüíæ Processed sample saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad29e06",
   "metadata": {},
   "source": [
    "## 6. Visualize Linguistic Metrics\n",
    "\n",
    "Let's create comprehensive visualizations to explore the distribution and relationships between different linguistic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976782d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations for stylometric metrics\n",
    "\n",
    "# Set up the plotting environment\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Stylometric and Linguistic Analysis - Distribution of Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Flesch Reading Ease Distribution\n",
    "if 'flesch_reading_ease' in df_processed.columns:\n",
    "    axes[0, 0].hist(df_processed['flesch_reading_ease'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Flesch Reading Ease Score Distribution')\n",
    "    axes[0, 0].set_xlabel('Score (Lower = More Complex)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].axvline(df_processed['flesch_reading_ease'].mean(), color='red', linestyle='--', label=f'Mean: {df_processed[\"flesch_reading_ease\"].mean():.1f}')\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "# 2. POS Frequencies Comparison\n",
    "pos_columns = [col for col in ['noun_freq', 'verb_freq', 'adj_freq', 'adv_freq'] if col in df_processed.columns]\n",
    "if pos_columns:\n",
    "    pos_means = [df_processed[col].mean() for col in pos_columns]\n",
    "    pos_labels = [col.replace('_freq', '').title() for col in pos_columns]\n",
    "    axes[0, 1].bar(pos_labels, pos_means, color=['lightcoral', 'lightgreen', 'lightyellow', 'lightblue'])\n",
    "    axes[0, 1].set_title('Average POS Frequencies (%)')\n",
    "    axes[0, 1].set_ylabel('Percentage')\n",
    "    for i, v in enumerate(pos_means):\n",
    "        axes[0, 1].text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# 3. Named Entity Counts\n",
    "entity_columns = [col for col in ['per_count', 'org_count', 'loc_count'] if col in df_processed.columns]\n",
    "if entity_columns:\n",
    "    entity_totals = [df_processed[col].sum() for col in entity_columns]\n",
    "    entity_labels = ['People (PER)', 'Organizations (ORG)', 'Locations (LOC)']\n",
    "    axes[0, 2].bar(entity_labels, entity_totals, color=['salmon', 'gold', 'lightseagreen'])\n",
    "    axes[0, 2].set_title('Total Named Entity Mentions')\n",
    "    axes[0, 2].set_ylabel('Count')\n",
    "    axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. TTR vs Flesch Reading Ease Correlation\n",
    "if 'ttr' in df_processed.columns and 'flesch_reading_ease' in df_processed.columns:\n",
    "    axes[1, 0].scatter(df_processed['ttr'], df_processed['flesch_reading_ease'], alpha=0.6)\n",
    "    axes[1, 0].set_xlabel('Type-Token Ratio (TTR)')\n",
    "    axes[1, 0].set_ylabel('Flesch Reading Ease')\n",
    "    axes[1, 0].set_title('TTR vs Reading Ease Correlation')\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    correlation = df_processed['ttr'].corr(df_processed['flesch_reading_ease'])\n",
    "    axes[1, 0].text(0.05, 0.95, f'r = {correlation:.3f}', transform=axes[1, 0].transAxes, \n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# 5. Metrics by Model (if model column exists)\n",
    "if 'model' in df_processed.columns and 'flesch_reading_ease' in df_processed.columns:\n",
    "    models = df_processed['model'].unique()\n",
    "    model_flesch = [df_processed[df_processed['model'] == model]['flesch_reading_ease'].mean() for model in models]\n",
    "    axes[1, 1].bar(models, model_flesch, color='lightsteelblue')\n",
    "    axes[1, 1].set_title('Average Reading Ease by Model')\n",
    "    axes[1, 1].set_ylabel('Flesch Reading Ease')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Additional Metrics Distribution\n",
    "additional_cols = [col for col in ['avg_word_length', 'long_words_ratio'] if col in df_processed.columns]\n",
    "if additional_cols:\n",
    "    for i, col in enumerate(additional_cols[:2]):  # Show max 2 additional metrics\n",
    "        if i == 0:\n",
    "            axes[1, 2].hist(df_processed[col], bins=15, alpha=0.7, color='mediumpurple', label=col)\n",
    "            axes[1, 2].set_xlabel(col.replace('_', ' ').title())\n",
    "            axes[1, 2].set_ylabel('Frequency')\n",
    "            axes[1, 2].set_title('Additional Metrics Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix for all numeric metrics\n",
    "numeric_columns = df_processed.select_dtypes(include=[np.number]).columns\n",
    "linguistic_metrics = [col for col in numeric_columns if col in new_columns + ['ttr', 'MLC', 'MLS', 'DCC', 'CPC']]\n",
    "\n",
    "if len(linguistic_metrics) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df_processed[linguistic_metrics].corr()\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "    \n",
    "    plt.title('Correlation Matrix: Stylometric and Linguistic Metrics', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Summary statistics table\n",
    "print(\"\\nüìä COMPREHENSIVE METRICS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(linguistic_metrics) > 0:\n",
    "    summary_stats = df_processed[linguistic_metrics].describe().round(2)\n",
    "    print(summary_stats)\n",
    "    \n",
    "    # Interpretation guide\n",
    "    print(\"\\nüìñ INTERPRETATION GUIDE:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"üî∏ Flesch Reading Ease: Lower scores = more complex text\")\n",
    "    print(\"üî∏ TTR (Type-Token Ratio): Higher values = more lexical diversity\")\n",
    "    print(\"üî∏ Noun Frequency: Higher % = nominal/informational style\")\n",
    "    print(\"üî∏ Verb Frequency: Higher % = narrative/action-oriented style\")\n",
    "    print(\"üî∏ Adjective/Adverb Frequency: Higher % = descriptive/evaluative style\")\n",
    "    print(\"üî∏ Named Entities: Higher counts = more references to actors/places\")\n",
    "else:\n",
    "    print(\"No linguistic metrics found for summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f7bae",
   "metadata": {},
   "source": [
    "## 7. Process Full Dataset (Optional)\n",
    "\n",
    "The following cells contain code to process the complete dataset. Uncomment and run when ready to analyze the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATASET PROCESSING - Uncomment when ready to process all data\n",
    "# \n",
    "# # This will process the entire dataset (may take 30+ minutes depending on size)\n",
    "# print(\"üöÄ Processing full dataset - this may take significant time...\")\n",
    "# \n",
    "# # Process in small batches to manage memory\n",
    "# df_full_processed = process_dataframe(df, text_column=text_column, batch_size=25)\n",
    "# \n",
    "# # Save the complete processed dataset\n",
    "# output_full_path = \"/home/igo/faculdade/poc/data/sentiment_results_with_stylometric.parquet\"\n",
    "# df_full_processed.to_parquet(output_full_path, index=False)\n",
    "# print(f\"‚úÖ Full processed dataset saved to: {output_full_path}\")\n",
    "# \n",
    "# # Display final summary\n",
    "# new_columns_full = [col for col in df_full_processed.columns if col not in df.columns]\n",
    "# print(f\"üìä Complete dataset: {len(df_full_processed)} rows with {len(new_columns_full)} new metrics\")\n",
    "\n",
    "print(\"üí° To process the full dataset:\")\n",
    "print(\"   1. Uncomment the code above\")\n",
    "print(\"   2. Run the cell\")\n",
    "print(\"   3. Wait for processing to complete\")\n",
    "print(\"   4. The enhanced dataset will be saved with all stylometric metrics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
